{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMhv2DLW8qw8",
        "outputId": "60896012-0d2b-4748-960f-3dc1ac3e9317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Niq6fSUoajNW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1op-CbyLuN4",
        "outputId": "ff3e0884-0ffb-40a4-d2d1-c4f72aee22b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 4.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 407 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.9 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpOAPFL6x19o"
      },
      "source": [
        "# Importing the data\n",
        "Using networkx, we load the edge list, combined with features obtained from encoding, into the right tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CscAUpGgWRA4",
        "outputId": "608687a9-4243-457c-9422-cbf49b36c5d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Graph with 217801 nodes and 1718164 edges'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import networkx as nx\n",
        "g = nx.read_edgelist(\"drive/MyDrive/Hindex/coauthorship.edgelist\",\n",
        "                     create_using=nx.Graph(), nodetype=int)\n",
        "nx.info(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zR4dbGBFlFT"
      },
      "source": [
        "Retrieve target attributes. We will give a arbitrary 0 hindex for test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNeB3ituaCHV",
        "outputId": "213a2152-ea47-442f-9fa6-3bbaf6f18710"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "174241"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "with open('drive/MyDrive/Hindex/train.csv', mode='r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(file)\n",
        "    nodes_attr = {rows[0] : float(rows[1]) for rows in reader} #string:float dic\n",
        "nx.set_node_attributes(g, nodes_attr)\n",
        "nx.info(g)\n",
        "len(list(set(nodes_attr.keys())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nTdxK5e28DQ"
      },
      "source": [
        "## Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPqzj8j2bo4E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import scipy.sparse\n",
        "from torch import Tensor\n",
        "from torch.utils.dlpack import to_dlpack, from_dlpack\n",
        "import torch_geometric.data\n",
        "\n",
        "data=torch_geometric.utils.from_networkx(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uCPgeorFx9G"
      },
      "source": [
        "Because data at hand is huge, we cannot give the whole labeled set as training data. We need to split it into training and test validation test, that will help us fine-tuning the hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nina3ST7pUNf"
      },
      "outputs": [],
      "source": [
        "def split_train_val(nodes, train_pct):\n",
        "  \"\"\"\n",
        "  Split dataset into train/val according to desired training percentage\n",
        "  Args:\n",
        "    nodes--dictionnary of annotated nodes (string : float)\n",
        "    train_pct--desired percentage of training nodes out of all annotated nodes (that represent 80% of all nodes)\n",
        "  \"\"\"\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  ids_train, ids_test_val, _ , _ = train_test_split(list(nodes.keys()),list(nodes.values()), test_size=int(len(nodes)*(1-train_pct)), shuffle=True)\n",
        "  dic_id_set={}\n",
        "  for id in ids_train:\n",
        "    dic_id_set[id]=True\n",
        "  for id in ids_test_val:\n",
        "    dic_id_set[id]=False\n",
        "  return dic_id_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOtU5wduwAEo"
      },
      "source": [
        "## Auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwWIZlm5kJuo"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open(\"/content/drive/MyDrive/Hindex/features_array.csv\",\"w+\", newline='') as my_csv:\n",
        "    csvWriter = csv.writer(my_csv,delimiter=';')\n",
        "    csvWriter.writerows(features_array)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkhkjx6-v5Io"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/Hindex/features_array.csv\", header=None, sep=\";\")\n",
        "\n",
        "features_array = df.values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqmm2XAgdq0g"
      },
      "outputs": [],
      "source": [
        "training_pct=0.2\n",
        "data.x = torch.tensor(features_array)\n",
        "dic_id_set = split_train_val(nodes_attr, 0.1)\n",
        "data.train_mask=torch.tensor([bool(dic_id_set[str(id)]) if str(id) in nodes_attr.keys() else False for id in g]) #boolean mask for nodes with hindex\n",
        "data.test_mask=torch.tensor([not bool(dic_id_set[str(id)]) if str(id) in nodes_attr.keys() else False for id in g]) #boolean mask for test nodes\n",
        "data.y=torch.tensor(np.array([nodes_attr[str(id)] if str(id) in nodes_attr.keys() else 0 for id in g], dtype=np.float32)) #node labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuE_bt0QBw-g",
        "outputId": "89418ab9-7167-4e92-9b27-26b6d394ba46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the nodes features: torch.Size([217801, 50])\n",
            "First 2 values:  tensor([[ 0.2918, -0.2287, -0.1525, -0.1800,  0.2448, -0.2673, -0.1754,  0.1103,\n",
            "          0.2178, -0.0363,  0.0883, -0.0080,  0.1367, -0.1285, -0.4137,  0.1007,\n",
            "          0.0897,  0.3045,  0.0669,  0.2519,  0.2660, -0.0081, -0.3811, -0.1297,\n",
            "          0.5370, -0.0743, -0.4923, -0.0941,  0.0967,  0.0494, -0.2042,  0.3060,\n",
            "         -0.0513,  0.3627, -0.0247,  0.3349, -0.5054,  0.1124,  0.6030,  0.1095,\n",
            "          0.1047, -0.4054, -0.2081,  0.3487,  0.3005, -0.3497, -0.1689, -0.0650,\n",
            "          0.1596,  0.1587],\n",
            "        [ 0.4811, -0.9494,  0.1138, -0.7336,  1.0302, -1.5913, -1.0252, -0.3283,\n",
            "          0.4168,  0.6787, -0.1083, -0.7383,  0.5772,  0.1212, -1.7845,  0.3229,\n",
            "          0.5518,  1.8893,  0.1943,  1.0873,  1.0742, -0.7111, -1.3113,  0.3635,\n",
            "          2.3933, -0.2809, -1.6479, -0.0770,  0.1659,  0.5000, -0.4000, -0.0677,\n",
            "          0.1566,  0.0181, -0.4468,  1.0730, -1.3070,  0.5717,  1.3567, -0.1255,\n",
            "          0.6775, -1.1167, -1.3318,  1.0357,  0.0526, -0.3599, -0.8329,  0.2774,\n",
            "          0.9822,  0.1123]]) \n",
            "\n",
            "Shape of the train mask tensor: torch.Size([217801])\n",
            "First ten values:  tensor([False, False, False, False, False, False, False, False, False, False]) \n",
            "\n",
            "Shape of the test mask tensor: torch.Size([217801])\n",
            "First ten values:  tensor([False, False, False,  True,  True,  True,  True,  True,  True, False]) \n",
            "\n",
            "Shape of the nodes attributes (what to predict): torch.Size([217801])\n",
            "First ten values:  tensor([ 0.,  0.,  0.,  1.,  1.,  1., 13., 11., 11.,  0.]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shape of the nodes features: {data.x.shape}\")\n",
        "print(\"First 2 values: \", data.x[:2], \"\\n\")\n",
        "print(f\"Shape of the train mask tensor: {data.train_mask.shape}\")\n",
        "print(\"First ten values: \", data.train_mask[:10], \"\\n\")\n",
        "print(f\"Shape of the test mask tensor: {data.test_mask.shape}\")\n",
        "print(\"First ten values: \", data.test_mask[:10], \"\\n\")\n",
        "print(f\"Shape of the nodes attributes (what to predict): {data.y.shape}\")\n",
        "print(\"First ten values: \", data.y[:10], \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imGrKO5YH11-",
        "outputId": "20ed110c-d0fb-4fd9-ca38-877518b2197d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 3436328], num_nodes=217801, x=[217801, 50], train_mask=[217801], test_mask=[217801], y=[217801])\n",
            "Number of nodes: 217801\n",
            "Number of edges: 3436328\n",
            "Average node degree: 15.78\n",
            "Number of training nodes: 17425\n",
            "Training node label rate: 0.08\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ],
      "source": [
        "print(data)\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IRdAELVKOl6"
      },
      "source": [
        "## Multi-layer Perception Network (MLP)\n",
        "A simple MLP that operates on input node features, not on the graph structure. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afXwPCA3KNoC",
        "outputId": "45dd6f19-a4a8-425d-8000-5a7c07e7744c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  (lin_layer_1): Linear(in_features=50, out_features=16, bias=True)\n",
            "  (lin_layer_2): Linear(in_features=16, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "num_features = len(features_array[0])\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(MLP, self).__init__()\n",
        "        torch.manual_seed(12345)\n",
        "        self.lin_layer_1 = Linear(num_features, hidden_channels)\n",
        "        self.lin_layer_2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.lin_layer_1(x)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin_layer_2(x)\n",
        "        return x\n",
        "\n",
        "model = MLP(hidden_channels=16)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YgHcLXMLk4o",
        "outputId": "b836cc73-b193-4b4d-f333-900eff0edc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0716],\n",
            "        [-0.0133],\n",
            "        [-0.2232],\n",
            "        ...,\n",
            "        [ 0.1683],\n",
            "        [10.7653],\n",
            "        [ 0.1511]], grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([17425])) that is different to the input size (torch.Size([17425, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 340.4165\n",
            "tensor([[ 1.3083e-02],\n",
            "        [-7.0432e-01],\n",
            "        [-1.2452e+00],\n",
            "        ...,\n",
            "        [-1.9554e-01],\n",
            "        [-6.5808e+01],\n",
            "        [-2.3271e+00]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 002, Loss: 791.9222\n",
            "tensor([[ 0.1777],\n",
            "        [ 0.2176],\n",
            "        [-0.2927],\n",
            "        ...,\n",
            "        [-0.0988],\n",
            "        [ 1.9274],\n",
            "        [ 0.2347]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 003, Loss: 359.0154\n",
            "tensor([[ 0.1959],\n",
            "        [ 0.5064],\n",
            "        [ 0.7297],\n",
            "        ...,\n",
            "        [ 0.2209],\n",
            "        [41.5082],\n",
            "        [ 2.1801]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 004, Loss: 324.9524\n",
            "tensor([[ 0.2908],\n",
            "        [ 0.8592],\n",
            "        [ 0.6202],\n",
            "        ...,\n",
            "        [ 0.5401],\n",
            "        [15.7827],\n",
            "        [ 2.6244]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 005, Loss: 555.5103\n",
            "tensor([[ 0.2305],\n",
            "        [ 0.3310],\n",
            "        [ 0.5949],\n",
            "        ...,\n",
            "        [-0.2329],\n",
            "        [ 5.9315],\n",
            "        [ 1.1048]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 006, Loss: 368.3228\n",
            "tensor([[  0.2239],\n",
            "        [  0.2402],\n",
            "        [  0.0798],\n",
            "        ...,\n",
            "        [ -0.3004],\n",
            "        [-51.7261],\n",
            "        [ -0.1047]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 007, Loss: 338.1847\n",
            "tensor([[  0.2341],\n",
            "        [  0.1461],\n",
            "        [ -0.5091],\n",
            "        ...,\n",
            "        [  0.2206],\n",
            "        [-43.0733],\n",
            "        [ -0.0492]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 008, Loss: 520.6283\n",
            "tensor([[ 0.1960],\n",
            "        [ 0.4748],\n",
            "        [ 0.6471],\n",
            "        ...,\n",
            "        [-0.0896],\n",
            "        [32.2952],\n",
            "        [-1.2217]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 009, Loss: 362.6980\n",
            "tensor([[ 0.1519],\n",
            "        [-0.1829],\n",
            "        [ 0.2734],\n",
            "        ...,\n",
            "        [ 0.4734],\n",
            "        [20.7017],\n",
            "        [ 0.1639]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 010, Loss: 329.0864\n",
            "tensor([[ 0.2201],\n",
            "        [ 0.2221],\n",
            "        [ 0.5032],\n",
            "        ...,\n",
            "        [ 0.8795],\n",
            "        [25.3198],\n",
            "        [ 0.5298]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 011, Loss: 381.7394\n",
            "tensor([[  0.2874],\n",
            "        [  0.0145],\n",
            "        [  0.5016],\n",
            "        ...,\n",
            "        [  0.3740],\n",
            "        [-10.2527],\n",
            "        [ -0.2604]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 012, Loss: 356.3383\n",
            "tensor([[ 0.3695],\n",
            "        [ 0.6431],\n",
            "        [ 0.3853],\n",
            "        ...,\n",
            "        [ 0.5824],\n",
            "        [65.0742],\n",
            "        [-0.4292]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 013, Loss: 448.0903\n",
            "tensor([[0.3649],\n",
            "        [0.6249],\n",
            "        [0.8966],\n",
            "        ...,\n",
            "        [0.0827],\n",
            "        [2.5105],\n",
            "        [1.4387]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 014, Loss: 315.6144\n",
            "tensor([[ 0.3476],\n",
            "        [ 0.4890],\n",
            "        [ 0.2289],\n",
            "        ...,\n",
            "        [ 0.3371],\n",
            "        [15.1287],\n",
            "        [ 0.8658]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 015, Loss: 285.8531\n",
            "tensor([[ 0.3220],\n",
            "        [ 0.1464],\n",
            "        [-0.0688],\n",
            "        ...,\n",
            "        [ 0.2548],\n",
            "        [-8.6303],\n",
            "        [ 0.5389]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 016, Loss: 291.9419\n",
            "tensor([[  0.4647],\n",
            "        [  0.3979],\n",
            "        [  0.5350],\n",
            "        ...,\n",
            "        [  0.1957],\n",
            "        [-37.1692],\n",
            "        [ -0.2069]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 017, Loss: 278.1760\n",
            "tensor([[ 0.3120],\n",
            "        [ 0.1845],\n",
            "        [ 0.4632],\n",
            "        ...,\n",
            "        [ 0.3552],\n",
            "        [-4.2838],\n",
            "        [ 1.3890]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 018, Loss: 329.1917\n",
            "tensor([[ 0.3087],\n",
            "        [ 0.2023],\n",
            "        [-0.4593],\n",
            "        ...,\n",
            "        [ 0.3356],\n",
            "        [ 3.2495],\n",
            "        [-0.3530]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 019, Loss: 295.7758\n",
            "tensor([[ 0.2681],\n",
            "        [ 0.4105],\n",
            "        [ 0.5150],\n",
            "        ...,\n",
            "        [ 0.3197],\n",
            "        [-3.0319],\n",
            "        [-0.4686]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 020, Loss: 283.0469\n",
            "tensor([[0.2205],\n",
            "        [0.5341],\n",
            "        [0.4572],\n",
            "        ...,\n",
            "        [0.2544],\n",
            "        [9.8799],\n",
            "        [0.5894]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 021, Loss: 269.6294\n",
            "tensor([[ 0.3668],\n",
            "        [ 0.4958],\n",
            "        [ 0.9662],\n",
            "        ...,\n",
            "        [ 0.5344],\n",
            "        [27.9847],\n",
            "        [ 0.4752]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 022, Loss: 286.8395\n",
            "tensor([[ 0.3720],\n",
            "        [ 0.4413],\n",
            "        [ 0.8320],\n",
            "        ...,\n",
            "        [ 0.7644],\n",
            "        [21.1580],\n",
            "        [ 0.0888]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 023, Loss: 312.2040\n",
            "tensor([[ 0.3747],\n",
            "        [ 0.3996],\n",
            "        [ 0.4849],\n",
            "        ...,\n",
            "        [ 0.4149],\n",
            "        [22.7861],\n",
            "        [ 0.5474]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 024, Loss: 296.6904\n",
            "tensor([[  0.4949],\n",
            "        [  0.4974],\n",
            "        [  0.4100],\n",
            "        ...,\n",
            "        [  0.6298],\n",
            "        [-13.0485],\n",
            "        [  1.1074]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 025, Loss: 264.7599\n",
            "tensor([[  0.4578],\n",
            "        [  0.6103],\n",
            "        [  0.0417],\n",
            "        ...,\n",
            "        [  0.4556],\n",
            "        [-21.5791],\n",
            "        [  1.2694]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 026, Loss: 281.6831\n",
            "tensor([[ 0.4646],\n",
            "        [ 0.4708],\n",
            "        [ 0.5529],\n",
            "        ...,\n",
            "        [ 0.3658],\n",
            "        [-7.8292],\n",
            "        [ 0.6559]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 027, Loss: 296.2651\n",
            "tensor([[  0.4601],\n",
            "        [  0.6074],\n",
            "        [  0.4185],\n",
            "        ...,\n",
            "        [  0.2852],\n",
            "        [-15.2234],\n",
            "        [  0.8537]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 028, Loss: 264.8020\n",
            "tensor([[ 0.3753],\n",
            "        [ 0.4321],\n",
            "        [ 0.3895],\n",
            "        ...,\n",
            "        [ 0.3850],\n",
            "        [20.2737],\n",
            "        [ 0.2695]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 029, Loss: 250.6570\n",
            "tensor([[ 0.4830],\n",
            "        [ 0.4374],\n",
            "        [ 0.6270],\n",
            "        ...,\n",
            "        [ 0.4107],\n",
            "        [13.1500],\n",
            "        [ 0.4288]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 030, Loss: 249.4178\n",
            "tensor([[0.5289],\n",
            "        [0.3806],\n",
            "        [0.5166],\n",
            "        ...,\n",
            "        [0.4512],\n",
            "        [4.8569],\n",
            "        [0.4572]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 031, Loss: 268.3634\n",
            "tensor([[ 0.4556],\n",
            "        [ 0.5583],\n",
            "        [ 0.4403],\n",
            "        ...,\n",
            "        [ 0.4579],\n",
            "        [-5.5045],\n",
            "        [ 0.4457]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 032, Loss: 281.8635\n",
            "tensor([[0.5653],\n",
            "        [0.5085],\n",
            "        [0.8200],\n",
            "        ...,\n",
            "        [0.5467],\n",
            "        [6.6135],\n",
            "        [0.1912]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 033, Loss: 251.3772\n",
            "tensor([[0.5887],\n",
            "        [0.4514],\n",
            "        [0.7148],\n",
            "        ...,\n",
            "        [0.6722],\n",
            "        [9.5575],\n",
            "        [0.3110]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 034, Loss: 252.0315\n",
            "tensor([[0.5426],\n",
            "        [0.4469],\n",
            "        [0.9239],\n",
            "        ...,\n",
            "        [0.6806],\n",
            "        [3.9659],\n",
            "        [0.9142]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 035, Loss: 253.2499\n",
            "tensor([[ 0.6265],\n",
            "        [ 0.6932],\n",
            "        [ 0.7075],\n",
            "        ...,\n",
            "        [ 0.6413],\n",
            "        [16.6216],\n",
            "        [ 0.7856]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 036, Loss: 262.0973\n",
            "tensor([[0.5072],\n",
            "        [0.8699],\n",
            "        [0.8628],\n",
            "        ...,\n",
            "        [0.5895],\n",
            "        [0.5272],\n",
            "        [0.7975]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 037, Loss: 271.8810\n",
            "tensor([[0.6636],\n",
            "        [0.6818],\n",
            "        [0.5756],\n",
            "        ...,\n",
            "        [0.5839],\n",
            "        [0.5935],\n",
            "        [1.7874]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 038, Loss: 252.7751\n",
            "tensor([[ 0.6354],\n",
            "        [ 0.8335],\n",
            "        [ 0.5005],\n",
            "        ...,\n",
            "        [ 0.5054],\n",
            "        [-3.8637],\n",
            "        [ 0.6221]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 039, Loss: 249.4591\n",
            "tensor([[ 0.6110],\n",
            "        [ 0.5620],\n",
            "        [ 0.4864],\n",
            "        ...,\n",
            "        [ 0.5133],\n",
            "        [-5.6102],\n",
            "        [ 0.8967]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 040, Loss: 252.1021\n",
            "tensor([[ 0.5696],\n",
            "        [ 0.6981],\n",
            "        [ 0.6524],\n",
            "        ...,\n",
            "        [ 0.5986],\n",
            "        [-8.0426],\n",
            "        [ 0.6228]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 041, Loss: 249.7245\n",
            "tensor([[0.5285],\n",
            "        [0.7856],\n",
            "        [0.6252],\n",
            "        ...,\n",
            "        [0.6321],\n",
            "        [1.0769],\n",
            "        [0.8605]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 042, Loss: 254.7337\n",
            "tensor([[ 0.6084],\n",
            "        [ 0.6430],\n",
            "        [ 0.3859],\n",
            "        ...,\n",
            "        [ 0.6124],\n",
            "        [-3.7087],\n",
            "        [ 0.3552]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 043, Loss: 260.8467\n",
            "tensor([[ 0.5870],\n",
            "        [ 0.5133],\n",
            "        [ 0.6903],\n",
            "        ...,\n",
            "        [ 0.5663],\n",
            "        [-4.0166],\n",
            "        [ 0.7675]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 044, Loss: 254.7893\n",
            "tensor([[0.6418],\n",
            "        [0.7336],\n",
            "        [0.5511],\n",
            "        ...,\n",
            "        [0.7624],\n",
            "        [7.3711],\n",
            "        [0.5497]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 045, Loss: 244.0370\n",
            "tensor([[0.7241],\n",
            "        [0.6539],\n",
            "        [0.7684],\n",
            "        ...,\n",
            "        [0.6360],\n",
            "        [6.2850],\n",
            "        [0.9930]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 046, Loss: 245.8529\n",
            "tensor([[ 0.7399],\n",
            "        [ 0.7998],\n",
            "        [ 0.7393],\n",
            "        ...,\n",
            "        [ 0.7762],\n",
            "        [12.0323],\n",
            "        [ 0.5250]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 047, Loss: 243.0759\n",
            "tensor([[0.6168],\n",
            "        [0.6851],\n",
            "        [0.7048],\n",
            "        ...,\n",
            "        [0.7987],\n",
            "        [4.7621],\n",
            "        [0.8516]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 048, Loss: 248.1741\n",
            "tensor([[0.6954],\n",
            "        [0.7665],\n",
            "        [0.9116],\n",
            "        ...,\n",
            "        [0.7811],\n",
            "        [6.5385],\n",
            "        [0.7380]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 049, Loss: 243.0107\n",
            "tensor([[0.7378],\n",
            "        [0.7456],\n",
            "        [0.7845],\n",
            "        ...,\n",
            "        [0.8116],\n",
            "        [4.6626],\n",
            "        [0.8094]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 050, Loss: 242.5636\n",
            "tensor([[ 0.8145],\n",
            "        [ 0.8645],\n",
            "        [ 0.8910],\n",
            "        ...,\n",
            "        [ 0.8545],\n",
            "        [-5.1004],\n",
            "        [ 0.9351]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 051, Loss: 240.3504\n",
            "tensor([[0.8388],\n",
            "        [0.6889],\n",
            "        [0.8959],\n",
            "        ...,\n",
            "        [0.9014],\n",
            "        [0.3274],\n",
            "        [0.9947]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 052, Loss: 239.7414\n",
            "tensor([[0.8391],\n",
            "        [0.7062],\n",
            "        [0.7468],\n",
            "        ...,\n",
            "        [0.8464],\n",
            "        [0.5125],\n",
            "        [0.8048]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 053, Loss: 244.2849\n",
            "tensor([[0.7804],\n",
            "        [0.8911],\n",
            "        [0.9555],\n",
            "        ...,\n",
            "        [0.8954],\n",
            "        [1.5686],\n",
            "        [0.8591]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 054, Loss: 239.8383\n",
            "tensor([[ 0.8625],\n",
            "        [ 0.6895],\n",
            "        [ 0.9670],\n",
            "        ...,\n",
            "        [ 0.9675],\n",
            "        [-0.8099],\n",
            "        [ 1.1324]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 055, Loss: 239.9022\n",
            "tensor([[0.8530],\n",
            "        [0.8650],\n",
            "        [0.8040],\n",
            "        ...,\n",
            "        [0.9274],\n",
            "        [7.5067],\n",
            "        [1.0210]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 056, Loss: 238.1358\n",
            "tensor([[0.8228],\n",
            "        [0.9327],\n",
            "        [0.8182],\n",
            "        ...,\n",
            "        [0.8722],\n",
            "        [1.3596],\n",
            "        [0.8686]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 057, Loss: 241.6888\n",
            "tensor([[0.8555],\n",
            "        [0.8381],\n",
            "        [1.0935],\n",
            "        ...,\n",
            "        [0.9013],\n",
            "        [4.5199],\n",
            "        [0.8290]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 058, Loss: 238.8291\n",
            "tensor([[0.9368],\n",
            "        [0.8840],\n",
            "        [0.9270],\n",
            "        ...,\n",
            "        [0.7894],\n",
            "        [8.0401],\n",
            "        [1.0732]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 059, Loss: 238.7688\n",
            "tensor([[0.9765],\n",
            "        [0.8598],\n",
            "        [1.0759],\n",
            "        ...,\n",
            "        [1.0043],\n",
            "        [6.0050],\n",
            "        [0.9004]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 060, Loss: 236.4945\n",
            "tensor([[0.9703],\n",
            "        [0.9550],\n",
            "        [1.0038],\n",
            "        ...,\n",
            "        [1.0844],\n",
            "        [4.7877],\n",
            "        [1.0949]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 061, Loss: 238.1767\n",
            "tensor([[1.0523],\n",
            "        [0.9360],\n",
            "        [1.1166],\n",
            "        ...,\n",
            "        [1.0074],\n",
            "        [9.4488],\n",
            "        [1.5674]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 062, Loss: 238.1941\n",
            "tensor([[0.9708],\n",
            "        [1.0643],\n",
            "        [0.9309],\n",
            "        ...,\n",
            "        [0.9947],\n",
            "        [6.6443],\n",
            "        [0.8994]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 063, Loss: 237.2862\n",
            "tensor([[1.0465],\n",
            "        [1.0190],\n",
            "        [1.0495],\n",
            "        ...,\n",
            "        [0.9077],\n",
            "        [2.7217],\n",
            "        [1.6117]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 064, Loss: 234.7835\n",
            "tensor([[ 1.0716],\n",
            "        [ 1.1574],\n",
            "        [ 1.1281],\n",
            "        ...,\n",
            "        [ 0.9982],\n",
            "        [10.8511],\n",
            "        [ 1.5600]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 065, Loss: 235.2354\n",
            "tensor([[0.9870],\n",
            "        [1.0186],\n",
            "        [1.0405],\n",
            "        ...,\n",
            "        [1.0250],\n",
            "        [7.1002],\n",
            "        [1.3714]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 066, Loss: 234.1638\n",
            "tensor([[1.0409],\n",
            "        [1.0798],\n",
            "        [1.1543],\n",
            "        ...,\n",
            "        [0.9434],\n",
            "        [6.9886],\n",
            "        [0.8977]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 067, Loss: 234.3528\n",
            "tensor([[ 1.0714],\n",
            "        [ 1.0340],\n",
            "        [ 1.1624],\n",
            "        ...,\n",
            "        [ 1.0715],\n",
            "        [-1.7942],\n",
            "        [ 0.9911]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 068, Loss: 232.1517\n",
            "tensor([[1.2960],\n",
            "        [1.1348],\n",
            "        [1.0681],\n",
            "        ...,\n",
            "        [1.1173],\n",
            "        [2.2492],\n",
            "        [1.3751]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 069, Loss: 233.4259\n",
            "tensor([[1.0943],\n",
            "        [1.3917],\n",
            "        [1.0520],\n",
            "        ...,\n",
            "        [1.1857],\n",
            "        [2.8317],\n",
            "        [1.3655]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 070, Loss: 232.3685\n",
            "tensor([[1.3782],\n",
            "        [1.1460],\n",
            "        [1.3694],\n",
            "        ...,\n",
            "        [1.4295],\n",
            "        [2.6868],\n",
            "        [1.3651]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 071, Loss: 230.6070\n",
            "tensor([[ 1.0826],\n",
            "        [ 1.4448],\n",
            "        [ 1.2074],\n",
            "        ...,\n",
            "        [ 1.3207],\n",
            "        [11.5935],\n",
            "        [ 1.1834]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 072, Loss: 230.4754\n",
            "tensor([[1.0091],\n",
            "        [1.3563],\n",
            "        [1.2072],\n",
            "        ...,\n",
            "        [1.5197],\n",
            "        [8.1285],\n",
            "        [1.4713]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 073, Loss: 231.7686\n",
            "tensor([[1.1924],\n",
            "        [1.2028],\n",
            "        [1.2704],\n",
            "        ...,\n",
            "        [1.4544],\n",
            "        [6.9584],\n",
            "        [1.3432]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 074, Loss: 230.4834\n",
            "tensor([[1.3583],\n",
            "        [1.5147],\n",
            "        [1.2132],\n",
            "        ...,\n",
            "        [1.2960],\n",
            "        [1.8595],\n",
            "        [1.3646]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 075, Loss: 228.0080\n",
            "tensor([[1.2695],\n",
            "        [1.4512],\n",
            "        [1.2562],\n",
            "        ...,\n",
            "        [1.4558],\n",
            "        [5.8324],\n",
            "        [1.7299]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 076, Loss: 227.9337\n",
            "tensor([[1.4372],\n",
            "        [1.5846],\n",
            "        [1.3338],\n",
            "        ...,\n",
            "        [1.3219],\n",
            "        [2.0918],\n",
            "        [1.6323]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 077, Loss: 228.3880\n",
            "tensor([[1.4714],\n",
            "        [1.5534],\n",
            "        [1.2363],\n",
            "        ...,\n",
            "        [1.4354],\n",
            "        [4.8253],\n",
            "        [1.8039]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 078, Loss: 227.2131\n",
            "tensor([[1.3951],\n",
            "        [1.6143],\n",
            "        [1.3237],\n",
            "        ...,\n",
            "        [1.4229],\n",
            "        [1.0633],\n",
            "        [1.9705]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 079, Loss: 225.9296\n",
            "tensor([[1.5327],\n",
            "        [1.4633],\n",
            "        [1.6128],\n",
            "        ...,\n",
            "        [1.4408],\n",
            "        [9.3360],\n",
            "        [2.4682]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 080, Loss: 225.1410\n",
            "tensor([[1.6585],\n",
            "        [1.7865],\n",
            "        [1.7109],\n",
            "        ...,\n",
            "        [1.7376],\n",
            "        [7.9751],\n",
            "        [1.9250]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 081, Loss: 223.4481\n",
            "tensor([[1.6803],\n",
            "        [1.6882],\n",
            "        [1.7744],\n",
            "        ...,\n",
            "        [1.7602],\n",
            "        [9.2444],\n",
            "        [1.9653]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 082, Loss: 223.2030\n",
            "tensor([[1.8003],\n",
            "        [1.7162],\n",
            "        [1.7073],\n",
            "        ...,\n",
            "        [1.8271],\n",
            "        [7.2522],\n",
            "        [1.7836]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 083, Loss: 222.5337\n",
            "tensor([[1.4854],\n",
            "        [1.5975],\n",
            "        [1.8759],\n",
            "        ...,\n",
            "        [1.5427],\n",
            "        [7.5938],\n",
            "        [2.1535]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 084, Loss: 221.0453\n",
            "tensor([[2.0514],\n",
            "        [1.6946],\n",
            "        [1.9695],\n",
            "        ...,\n",
            "        [2.1167],\n",
            "        [8.7149],\n",
            "        [2.3320]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 085, Loss: 220.7699\n",
            "tensor([[2.0369],\n",
            "        [2.0234],\n",
            "        [2.2956],\n",
            "        ...,\n",
            "        [2.1077],\n",
            "        [4.2174],\n",
            "        [2.9042]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 086, Loss: 218.9707\n",
            "tensor([[2.0054],\n",
            "        [2.1355],\n",
            "        [2.3938],\n",
            "        ...,\n",
            "        [1.8190],\n",
            "        [3.8768],\n",
            "        [2.0194]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 087, Loss: 218.5118\n",
            "tensor([[1.9344],\n",
            "        [2.3628],\n",
            "        [2.0873],\n",
            "        ...,\n",
            "        [2.3548],\n",
            "        [3.7604],\n",
            "        [2.8260]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 088, Loss: 217.4119\n",
            "tensor([[1.7528],\n",
            "        [1.6188],\n",
            "        [2.3054],\n",
            "        ...,\n",
            "        [1.9029],\n",
            "        [7.0302],\n",
            "        [2.7821]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 089, Loss: 216.1143\n",
            "tensor([[1.8852],\n",
            "        [2.3088],\n",
            "        [2.6581],\n",
            "        ...,\n",
            "        [2.5297],\n",
            "        [2.3348],\n",
            "        [3.2310]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 090, Loss: 216.0528\n",
            "tensor([[2.5862],\n",
            "        [2.4883],\n",
            "        [1.9416],\n",
            "        ...,\n",
            "        [2.7146],\n",
            "        [3.1921],\n",
            "        [2.9715]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 091, Loss: 214.3862\n",
            "tensor([[2.4554],\n",
            "        [2.2708],\n",
            "        [1.9658],\n",
            "        ...,\n",
            "        [2.5929],\n",
            "        [4.2597],\n",
            "        [3.0794]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 092, Loss: 214.5747\n",
            "tensor([[2.0952],\n",
            "        [2.3171],\n",
            "        [1.9855],\n",
            "        ...,\n",
            "        [2.7943],\n",
            "        [6.5843],\n",
            "        [3.0003]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 093, Loss: 212.5485\n",
            "tensor([[2.5265],\n",
            "        [2.4343],\n",
            "        [2.4275],\n",
            "        ...,\n",
            "        [2.4795],\n",
            "        [2.1324],\n",
            "        [3.4145]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 094, Loss: 210.8596\n",
            "tensor([[2.7295],\n",
            "        [3.3180],\n",
            "        [2.3632],\n",
            "        ...,\n",
            "        [2.4182],\n",
            "        [7.8214],\n",
            "        [2.8530]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 095, Loss: 210.8441\n",
            "tensor([[2.4861],\n",
            "        [2.3725],\n",
            "        [2.7035],\n",
            "        ...,\n",
            "        [2.1060],\n",
            "        [9.6106],\n",
            "        [3.7937]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 096, Loss: 209.5772\n",
            "tensor([[2.4619],\n",
            "        [2.8276],\n",
            "        [2.3716],\n",
            "        ...,\n",
            "        [1.9912],\n",
            "        [0.3843],\n",
            "        [3.5655]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 097, Loss: 207.0231\n",
            "tensor([[2.9390],\n",
            "        [3.1448],\n",
            "        [2.9743],\n",
            "        ...,\n",
            "        [2.9073],\n",
            "        [7.2063],\n",
            "        [2.9810]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 098, Loss: 206.2112\n",
            "tensor([[2.7574],\n",
            "        [2.2852],\n",
            "        [2.8243],\n",
            "        ...,\n",
            "        [3.0697],\n",
            "        [1.6869],\n",
            "        [4.4895]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 099, Loss: 205.4690\n",
            "tensor([[3.1253],\n",
            "        [2.8332],\n",
            "        [3.0479],\n",
            "        ...,\n",
            "        [3.0843],\n",
            "        [4.7748],\n",
            "        [3.8782]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 100, Loss: 204.1689\n",
            "tensor([[ 3.6906],\n",
            "        [ 3.9552],\n",
            "        [ 2.6831],\n",
            "        ...,\n",
            "        [ 3.3842],\n",
            "        [10.4083],\n",
            "        [ 3.6042]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 101, Loss: 203.5599\n",
            "tensor([[2.7762],\n",
            "        [2.9345],\n",
            "        [3.5684],\n",
            "        ...,\n",
            "        [3.4433],\n",
            "        [9.8192],\n",
            "        [3.6950]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 102, Loss: 202.9076\n",
            "tensor([[2.5494],\n",
            "        [3.0834],\n",
            "        [3.6235],\n",
            "        ...,\n",
            "        [3.6948],\n",
            "        [5.2788],\n",
            "        [4.0739]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 103, Loss: 199.0719\n",
            "tensor([[ 3.3861],\n",
            "        [ 4.0950],\n",
            "        [ 3.1640],\n",
            "        ...,\n",
            "        [ 3.6484],\n",
            "        [14.3365],\n",
            "        [ 4.2589]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 104, Loss: 199.2698\n",
            "tensor([[3.5530],\n",
            "        [3.7065],\n",
            "        [2.9068],\n",
            "        ...,\n",
            "        [3.3996],\n",
            "        [9.1035],\n",
            "        [3.9342]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 105, Loss: 199.0578\n",
            "tensor([[3.2642],\n",
            "        [2.9922],\n",
            "        [3.8078],\n",
            "        ...,\n",
            "        [3.1927],\n",
            "        [5.5633],\n",
            "        [3.6404]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 106, Loss: 196.5695\n",
            "tensor([[ 3.4839],\n",
            "        [ 3.2406],\n",
            "        [ 3.8276],\n",
            "        ...,\n",
            "        [ 3.4232],\n",
            "        [16.2266],\n",
            "        [ 3.9980]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 107, Loss: 194.1008\n",
            "tensor([[4.2496],\n",
            "        [4.6690],\n",
            "        [3.2319],\n",
            "        ...,\n",
            "        [3.9433],\n",
            "        [9.8217],\n",
            "        [3.3338]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 108, Loss: 194.6138\n",
            "tensor([[ 4.1080],\n",
            "        [ 4.9126],\n",
            "        [ 3.1868],\n",
            "        ...,\n",
            "        [ 4.4601],\n",
            "        [11.8931],\n",
            "        [ 4.3384]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 109, Loss: 191.9648\n",
            "tensor([[ 5.0654],\n",
            "        [ 2.9810],\n",
            "        [ 4.4275],\n",
            "        ...,\n",
            "        [ 4.3564],\n",
            "        [12.2047],\n",
            "        [ 4.4428]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 110, Loss: 192.1125\n",
            "tensor([[4.0748],\n",
            "        [4.4614],\n",
            "        [4.4219],\n",
            "        ...,\n",
            "        [2.5606],\n",
            "        [9.3278],\n",
            "        [2.8968]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 111, Loss: 188.2942\n",
            "tensor([[4.0059],\n",
            "        [4.9491],\n",
            "        [3.3775],\n",
            "        ...,\n",
            "        [4.4549],\n",
            "        [0.0383],\n",
            "        [4.4295]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 112, Loss: 191.2603\n",
            "tensor([[5.0467],\n",
            "        [4.3596],\n",
            "        [4.9239],\n",
            "        ...,\n",
            "        [4.4648],\n",
            "        [8.3396],\n",
            "        [4.9452]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 113, Loss: 190.5205\n",
            "tensor([[ 5.0034],\n",
            "        [ 4.4233],\n",
            "        [ 5.3712],\n",
            "        ...,\n",
            "        [ 5.1185],\n",
            "        [19.2223],\n",
            "        [ 4.1441]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 114, Loss: 185.9978\n",
            "tensor([[ 5.6431],\n",
            "        [ 4.1457],\n",
            "        [ 4.8465],\n",
            "        ...,\n",
            "        [ 4.9485],\n",
            "        [15.6664],\n",
            "        [ 5.4870]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 115, Loss: 184.5287\n",
            "tensor([[5.3164],\n",
            "        [5.0641],\n",
            "        [6.1584],\n",
            "        ...,\n",
            "        [4.2591],\n",
            "        [9.9605],\n",
            "        [5.4842]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 116, Loss: 184.1548\n",
            "tensor([[ 4.1269],\n",
            "        [ 5.6593],\n",
            "        [ 5.4853],\n",
            "        ...,\n",
            "        [ 5.1079],\n",
            "        [15.3406],\n",
            "        [ 5.9562]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 117, Loss: 185.0090\n",
            "tensor([[ 4.7392],\n",
            "        [ 5.6898],\n",
            "        [ 4.9159],\n",
            "        ...,\n",
            "        [ 4.4848],\n",
            "        [17.4882],\n",
            "        [ 5.5403]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 118, Loss: 188.5959\n",
            "tensor([[5.6370],\n",
            "        [4.5099],\n",
            "        [5.5094],\n",
            "        ...,\n",
            "        [6.7570],\n",
            "        [7.7337],\n",
            "        [5.0097]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 119, Loss: 183.6075\n",
            "tensor([[ 6.4953],\n",
            "        [ 5.2610],\n",
            "        [ 5.0624],\n",
            "        ...,\n",
            "        [ 6.9372],\n",
            "        [20.6928],\n",
            "        [ 6.0037]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 120, Loss: 183.2669\n",
            "tensor([[ 7.5439],\n",
            "        [ 6.6958],\n",
            "        [ 7.2049],\n",
            "        ...,\n",
            "        [ 5.7445],\n",
            "        [34.4489],\n",
            "        [ 6.6576]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 121, Loss: 179.3394\n",
            "tensor([[ 5.5980],\n",
            "        [ 6.0603],\n",
            "        [ 4.9648],\n",
            "        ...,\n",
            "        [ 5.9850],\n",
            "        [37.8197],\n",
            "        [ 7.3495]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 122, Loss: 186.2031\n",
            "tensor([[4.4571],\n",
            "        [5.2762],\n",
            "        [5.6569],\n",
            "        ...,\n",
            "        [5.8923],\n",
            "        [0.5388],\n",
            "        [7.7952]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 123, Loss: 177.2785\n",
            "tensor([[ 5.2758],\n",
            "        [ 5.9511],\n",
            "        [ 4.9618],\n",
            "        ...,\n",
            "        [ 5.6712],\n",
            "        [20.3046],\n",
            "        [ 7.9082]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 124, Loss: 177.5793\n",
            "tensor([[ 4.9199],\n",
            "        [ 6.3835],\n",
            "        [ 5.0868],\n",
            "        ...,\n",
            "        [ 4.9448],\n",
            "        [40.1351],\n",
            "        [ 7.2050]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 125, Loss: 183.3055\n",
            "tensor([[ 6.8031],\n",
            "        [ 6.3410],\n",
            "        [ 6.6068],\n",
            "        ...,\n",
            "        [ 5.5334],\n",
            "        [20.4378],\n",
            "        [ 6.3139]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 126, Loss: 177.0920\n",
            "tensor([[ 6.7473],\n",
            "        [ 6.2117],\n",
            "        [ 6.1646],\n",
            "        ...,\n",
            "        [ 5.1713],\n",
            "        [20.0765],\n",
            "        [ 7.1681]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 127, Loss: 175.0654\n",
            "tensor([[ 5.9767],\n",
            "        [ 7.8604],\n",
            "        [ 6.6577],\n",
            "        ...,\n",
            "        [ 4.9237],\n",
            "        [24.2129],\n",
            "        [ 9.2646]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 128, Loss: 177.1265\n",
            "tensor([[ 5.1219],\n",
            "        [ 9.4033],\n",
            "        [ 5.4402],\n",
            "        ...,\n",
            "        [ 6.7548],\n",
            "        [21.3958],\n",
            "        [ 5.8619]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 129, Loss: 176.5881\n",
            "tensor([[ 5.7693],\n",
            "        [ 5.4481],\n",
            "        [ 6.5513],\n",
            "        ...,\n",
            "        [ 6.8021],\n",
            "        [25.8404],\n",
            "        [ 5.5603]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 130, Loss: 176.0808\n",
            "tensor([[ 5.8525],\n",
            "        [ 4.9675],\n",
            "        [ 7.1205],\n",
            "        ...,\n",
            "        [ 8.5836],\n",
            "        [20.8907],\n",
            "        [ 6.0620]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 131, Loss: 172.2137\n",
            "tensor([[ 5.7353],\n",
            "        [ 5.8294],\n",
            "        [ 5.2618],\n",
            "        ...,\n",
            "        [ 7.2886],\n",
            "        [15.4015],\n",
            "        [ 7.3361]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 132, Loss: 174.0591\n",
            "tensor([[ 7.2372],\n",
            "        [ 5.6172],\n",
            "        [ 3.9976],\n",
            "        ...,\n",
            "        [ 4.8432],\n",
            "        [17.6182],\n",
            "        [ 7.5442]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 133, Loss: 172.4859\n",
            "tensor([[7.7643],\n",
            "        [6.1237],\n",
            "        [9.8902],\n",
            "        ...,\n",
            "        [6.3275],\n",
            "        [9.0982],\n",
            "        [6.6887]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 134, Loss: 171.1951\n",
            "tensor([[ 6.7960],\n",
            "        [ 8.2482],\n",
            "        [ 7.1526],\n",
            "        ...,\n",
            "        [ 6.8139],\n",
            "        [18.4931],\n",
            "        [ 9.9759]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 135, Loss: 188.4375\n",
            "tensor([[ 6.3815],\n",
            "        [ 7.6551],\n",
            "        [ 6.9102],\n",
            "        ...,\n",
            "        [ 7.2597],\n",
            "        [20.7459],\n",
            "        [ 8.1961]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 136, Loss: 174.0360\n",
            "tensor([[ 8.1145],\n",
            "        [ 8.0625],\n",
            "        [ 7.3478],\n",
            "        ...,\n",
            "        [ 4.8863],\n",
            "        [14.7292],\n",
            "        [10.4541]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 137, Loss: 172.1223\n",
            "tensor([[7.8652],\n",
            "        [8.8474],\n",
            "        [7.3315],\n",
            "        ...,\n",
            "        [9.1463],\n",
            "        [1.3214],\n",
            "        [6.2317]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 138, Loss: 170.3517\n",
            "tensor([[ 8.6583],\n",
            "        [ 8.7865],\n",
            "        [ 7.2549],\n",
            "        ...,\n",
            "        [ 8.8625],\n",
            "        [21.1554],\n",
            "        [ 5.4761]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 139, Loss: 178.5029\n",
            "tensor([[ 7.6869],\n",
            "        [ 7.5306],\n",
            "        [ 5.2033],\n",
            "        ...,\n",
            "        [10.5584],\n",
            "        [44.4191],\n",
            "        [ 8.3333]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 140, Loss: 179.7077\n",
            "tensor([[ 6.1240],\n",
            "        [ 8.4993],\n",
            "        [ 6.7727],\n",
            "        ...,\n",
            "        [ 7.3900],\n",
            "        [25.7288],\n",
            "        [ 7.5495]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 141, Loss: 178.7046\n",
            "tensor([[ 5.8444],\n",
            "        [ 9.5390],\n",
            "        [ 4.9256],\n",
            "        ...,\n",
            "        [ 6.8619],\n",
            "        [32.3131],\n",
            "        [10.2162]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 142, Loss: 178.7017\n",
            "tensor([[ 9.6323],\n",
            "        [ 8.2326],\n",
            "        [ 5.8097],\n",
            "        ...,\n",
            "        [ 6.5236],\n",
            "        [28.2512],\n",
            "        [ 9.7484]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 143, Loss: 183.0335\n",
            "tensor([[ 7.5675],\n",
            "        [ 7.3297],\n",
            "        [ 6.8784],\n",
            "        ...,\n",
            "        [ 9.5387],\n",
            "        [27.6356],\n",
            "        [10.5714]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 144, Loss: 176.9487\n",
            "tensor([[ 6.5120],\n",
            "        [ 7.3132],\n",
            "        [ 7.4488],\n",
            "        ...,\n",
            "        [ 6.3895],\n",
            "        [27.7055],\n",
            "        [10.3983]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 145, Loss: 175.1728\n",
            "tensor([[ 6.8823],\n",
            "        [ 6.7865],\n",
            "        [ 8.5745],\n",
            "        ...,\n",
            "        [ 3.5596],\n",
            "        [35.8638],\n",
            "        [ 8.6361]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 146, Loss: 176.6899\n",
            "tensor([[ 7.5417],\n",
            "        [ 4.6739],\n",
            "        [ 8.7649],\n",
            "        ...,\n",
            "        [ 9.0761],\n",
            "        [38.3753],\n",
            "        [ 4.5747]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 147, Loss: 227.1699\n",
            "tensor([[ 7.2565],\n",
            "        [ 8.8599],\n",
            "        [ 6.7071],\n",
            "        ...,\n",
            "        [ 7.8620],\n",
            "        [14.2805],\n",
            "        [13.8624]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 148, Loss: 169.6223\n",
            "tensor([[ 8.3686],\n",
            "        [ 6.6063],\n",
            "        [ 5.5321],\n",
            "        ...,\n",
            "        [ 9.3008],\n",
            "        [-1.8312],\n",
            "        [12.1449]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 149, Loss: 197.9473\n",
            "tensor([[ 6.7366],\n",
            "        [ 9.5317],\n",
            "        [ 7.3195],\n",
            "        ...,\n",
            "        [ 8.4462],\n",
            "        [17.9480],\n",
            "        [ 8.8324]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 150, Loss: 168.2728\n",
            "tensor([[ 7.1269],\n",
            "        [ 6.6053],\n",
            "        [10.1218],\n",
            "        ...,\n",
            "        [ 7.8142],\n",
            "        [34.7727],\n",
            "        [ 6.6161]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 151, Loss: 181.5690\n",
            "tensor([[ 6.8992],\n",
            "        [ 5.5263],\n",
            "        [ 6.8583],\n",
            "        ...,\n",
            "        [ 8.2506],\n",
            "        [18.6369],\n",
            "        [ 8.4191]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 152, Loss: 185.9008\n",
            "tensor([[ 6.4944],\n",
            "        [ 7.7939],\n",
            "        [ 6.8949],\n",
            "        ...,\n",
            "        [ 8.2973],\n",
            "        [15.4962],\n",
            "        [ 9.2807]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 153, Loss: 176.7322\n",
            "tensor([[ 7.0182],\n",
            "        [ 9.4509],\n",
            "        [ 6.8436],\n",
            "        ...,\n",
            "        [ 9.8714],\n",
            "        [41.7571],\n",
            "        [11.4559]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 154, Loss: 177.4027\n",
            "tensor([[8.3287],\n",
            "        [8.3501],\n",
            "        [7.5859],\n",
            "        ...,\n",
            "        [5.5975],\n",
            "        [7.2012],\n",
            "        [5.2237]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 155, Loss: 174.5541\n",
            "tensor([[ 7.0010],\n",
            "        [ 8.0371],\n",
            "        [ 8.8759],\n",
            "        ...,\n",
            "        [ 6.5061],\n",
            "        [ 9.8563],\n",
            "        [12.3491]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 156, Loss: 189.3334\n",
            "tensor([[ 6.2372],\n",
            "        [ 7.9618],\n",
            "        [ 9.2028],\n",
            "        ...,\n",
            "        [ 5.0497],\n",
            "        [19.7584],\n",
            "        [ 9.5866]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 157, Loss: 186.1645\n",
            "tensor([[ 7.1758],\n",
            "        [ 8.2911],\n",
            "        [ 6.0745],\n",
            "        ...,\n",
            "        [ 9.3662],\n",
            "        [50.5381],\n",
            "        [10.0517]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 158, Loss: 172.6953\n",
            "tensor([[ 7.7390],\n",
            "        [ 6.4515],\n",
            "        [ 8.8725],\n",
            "        ...,\n",
            "        [ 7.8740],\n",
            "        [29.6089],\n",
            "        [10.5274]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 159, Loss: 175.6448\n",
            "tensor([[ 9.5605],\n",
            "        [ 9.6628],\n",
            "        [ 6.6575],\n",
            "        ...,\n",
            "        [ 7.1489],\n",
            "        [25.3613],\n",
            "        [ 9.1507]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 160, Loss: 175.6920\n",
            "tensor([[ 7.9208],\n",
            "        [ 8.3355],\n",
            "        [ 8.4164],\n",
            "        ...,\n",
            "        [ 6.6741],\n",
            "        [36.4337],\n",
            "        [ 8.2498]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 161, Loss: 185.7439\n",
            "tensor([[ 7.4009],\n",
            "        [ 7.8373],\n",
            "        [ 9.2364],\n",
            "        ...,\n",
            "        [ 7.5102],\n",
            "        [17.7514],\n",
            "        [11.0266]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 162, Loss: 179.9336\n",
            "tensor([[ 6.5065],\n",
            "        [ 8.2069],\n",
            "        [ 7.6250],\n",
            "        ...,\n",
            "        [ 8.6089],\n",
            "        [17.6551],\n",
            "        [ 5.9988]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 163, Loss: 173.6328\n",
            "tensor([[ 6.2345],\n",
            "        [10.4685],\n",
            "        [ 7.8662],\n",
            "        ...,\n",
            "        [10.1438],\n",
            "        [35.0568],\n",
            "        [ 7.7976]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 164, Loss: 175.2658\n",
            "tensor([[ 8.3214],\n",
            "        [ 6.8934],\n",
            "        [ 9.4532],\n",
            "        ...,\n",
            "        [ 8.9149],\n",
            "        [45.2061],\n",
            "        [ 9.6256]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 165, Loss: 183.2238\n",
            "tensor([[ 8.8663],\n",
            "        [ 7.8634],\n",
            "        [ 9.7914],\n",
            "        ...,\n",
            "        [ 6.9868],\n",
            "        [13.5081],\n",
            "        [ 6.7510]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 166, Loss: 174.7689\n",
            "tensor([[ 6.6605],\n",
            "        [ 8.9265],\n",
            "        [ 8.3834],\n",
            "        ...,\n",
            "        [ 8.9775],\n",
            "        [44.6738],\n",
            "        [ 7.7299]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 167, Loss: 169.5461\n",
            "tensor([[ 7.7643],\n",
            "        [ 9.4798],\n",
            "        [ 7.9006],\n",
            "        ...,\n",
            "        [ 7.5751],\n",
            "        [28.5775],\n",
            "        [ 8.8858]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 168, Loss: 179.0223\n",
            "tensor([[ 8.6610],\n",
            "        [ 8.4442],\n",
            "        [ 8.0846],\n",
            "        ...,\n",
            "        [ 9.9083],\n",
            "        [37.6577],\n",
            "        [ 6.7803]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 169, Loss: 172.1189\n",
            "tensor([[ 7.1231],\n",
            "        [ 6.5178],\n",
            "        [ 9.8173],\n",
            "        ...,\n",
            "        [ 6.5473],\n",
            "        [21.9832],\n",
            "        [ 7.8395]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 170, Loss: 170.5196\n",
            "tensor([[ 7.0463],\n",
            "        [ 8.0117],\n",
            "        [ 7.5576],\n",
            "        ...,\n",
            "        [ 7.1669],\n",
            "        [63.6400],\n",
            "        [ 9.2501]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 171, Loss: 172.8465\n",
            "tensor([[10.5108],\n",
            "        [ 9.8227],\n",
            "        [ 7.3678],\n",
            "        ...,\n",
            "        [ 8.8399],\n",
            "        [62.9952],\n",
            "        [ 9.0555]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 172, Loss: 169.9885\n",
            "tensor([[ 7.4903],\n",
            "        [10.0864],\n",
            "        [ 6.5360],\n",
            "        ...,\n",
            "        [ 9.1235],\n",
            "        [31.7914],\n",
            "        [ 8.7685]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 173, Loss: 180.3505\n",
            "tensor([[ 8.3041],\n",
            "        [ 7.4177],\n",
            "        [ 5.9715],\n",
            "        ...,\n",
            "        [ 7.8118],\n",
            "        [45.1400],\n",
            "        [12.2436]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 174, Loss: 167.9843\n",
            "tensor([[ 8.4503],\n",
            "        [ 6.9964],\n",
            "        [ 6.3526],\n",
            "        ...,\n",
            "        [ 8.7491],\n",
            "        [26.0578],\n",
            "        [11.3384]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 175, Loss: 167.7310\n",
            "tensor([[10.7081],\n",
            "        [ 5.5432],\n",
            "        [ 6.8785],\n",
            "        ...,\n",
            "        [ 8.6085],\n",
            "        [15.8220],\n",
            "        [ 8.7325]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 176, Loss: 170.7668\n",
            "tensor([[ 6.7316],\n",
            "        [ 7.5478],\n",
            "        [ 7.8247],\n",
            "        ...,\n",
            "        [ 5.5360],\n",
            "        [22.2253],\n",
            "        [ 7.9814]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 177, Loss: 166.2633\n",
            "tensor([[ 9.1193],\n",
            "        [ 9.7011],\n",
            "        [ 8.1850],\n",
            "        ...,\n",
            "        [ 6.7292],\n",
            "        [26.0976],\n",
            "        [ 7.9740]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 178, Loss: 174.5433\n",
            "tensor([[ 8.9072],\n",
            "        [ 9.3762],\n",
            "        [ 9.2728],\n",
            "        ...,\n",
            "        [ 7.8391],\n",
            "        [33.2768],\n",
            "        [ 6.7111]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 179, Loss: 168.4541\n",
            "tensor([[ 9.7244],\n",
            "        [ 7.6438],\n",
            "        [ 8.5018],\n",
            "        ...,\n",
            "        [ 6.1048],\n",
            "        [32.1820],\n",
            "        [ 9.9842]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 180, Loss: 167.0245\n",
            "tensor([[ 7.6366],\n",
            "        [ 9.2743],\n",
            "        [ 5.8415],\n",
            "        ...,\n",
            "        [ 7.7080],\n",
            "        [61.0265],\n",
            "        [ 7.0824]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 181, Loss: 169.1831\n",
            "tensor([[ 8.1502],\n",
            "        [ 7.9531],\n",
            "        [11.4557],\n",
            "        ...,\n",
            "        [ 6.7163],\n",
            "        [38.2668],\n",
            "        [ 5.7100]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 182, Loss: 168.0936\n",
            "tensor([[ 6.5241],\n",
            "        [ 6.1055],\n",
            "        [ 6.5947],\n",
            "        ...,\n",
            "        [ 6.5664],\n",
            "        [49.9755],\n",
            "        [ 7.1508]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 183, Loss: 167.5180\n",
            "tensor([[ 6.9933],\n",
            "        [ 8.9918],\n",
            "        [11.6732],\n",
            "        ...,\n",
            "        [ 8.7173],\n",
            "        [66.9508],\n",
            "        [ 5.9023]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 184, Loss: 165.1935\n",
            "tensor([[10.8030],\n",
            "        [ 8.6439],\n",
            "        [ 6.5186],\n",
            "        ...,\n",
            "        [ 7.9122],\n",
            "        [37.9212],\n",
            "        [ 9.6354]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 185, Loss: 164.8959\n",
            "tensor([[ 5.7764],\n",
            "        [ 5.9729],\n",
            "        [ 7.4545],\n",
            "        ...,\n",
            "        [ 6.4764],\n",
            "        [42.3831],\n",
            "        [ 9.6932]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 186, Loss: 168.3101\n",
            "tensor([[ 9.5636],\n",
            "        [10.5429],\n",
            "        [ 9.7546],\n",
            "        ...,\n",
            "        [ 8.6941],\n",
            "        [67.9495],\n",
            "        [ 4.8559]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 187, Loss: 170.2928\n",
            "tensor([[ 9.8322],\n",
            "        [ 6.3886],\n",
            "        [ 7.6842],\n",
            "        ...,\n",
            "        [ 8.7783],\n",
            "        [54.5575],\n",
            "        [ 8.9959]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 188, Loss: 171.9303\n",
            "tensor([[ 8.0783],\n",
            "        [ 9.7551],\n",
            "        [ 8.5833],\n",
            "        ...,\n",
            "        [ 6.8858],\n",
            "        [21.1620],\n",
            "        [11.8080]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 189, Loss: 168.8499\n",
            "tensor([[ 5.8336],\n",
            "        [ 9.2679],\n",
            "        [ 6.5881],\n",
            "        ...,\n",
            "        [ 7.5732],\n",
            "        [34.5587],\n",
            "        [ 9.6824]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 190, Loss: 164.6976\n",
            "tensor([[9.1499],\n",
            "        [7.3962],\n",
            "        [6.2905],\n",
            "        ...,\n",
            "        [6.5882],\n",
            "        [6.6903],\n",
            "        [9.2344]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 191, Loss: 164.1113\n",
            "tensor([[ 8.9249],\n",
            "        [ 9.2457],\n",
            "        [ 9.2219],\n",
            "        ...,\n",
            "        [ 9.1928],\n",
            "        [56.3136],\n",
            "        [11.2003]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 192, Loss: 162.3835\n",
            "tensor([[ 7.0020],\n",
            "        [11.0243],\n",
            "        [ 8.2260],\n",
            "        ...,\n",
            "        [10.7775],\n",
            "        [54.5388],\n",
            "        [ 9.2896]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 193, Loss: 169.2330\n",
            "tensor([[ 7.3695],\n",
            "        [ 8.9523],\n",
            "        [ 8.1569],\n",
            "        ...,\n",
            "        [ 6.9504],\n",
            "        [15.1179],\n",
            "        [ 5.7981]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 194, Loss: 167.8272\n",
            "tensor([[11.5890],\n",
            "        [ 6.5519],\n",
            "        [11.3660],\n",
            "        ...,\n",
            "        [ 9.8060],\n",
            "        [45.8955],\n",
            "        [13.4344]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 195, Loss: 164.4888\n",
            "tensor([[11.4342],\n",
            "        [ 7.1889],\n",
            "        [ 7.8552],\n",
            "        ...,\n",
            "        [ 5.9128],\n",
            "        [36.4518],\n",
            "        [ 9.8772]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 196, Loss: 164.5454\n",
            "tensor([[10.9169],\n",
            "        [ 8.7693],\n",
            "        [11.5459],\n",
            "        ...,\n",
            "        [ 8.4175],\n",
            "        [38.1952],\n",
            "        [ 9.3525]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 197, Loss: 166.0437\n",
            "tensor([[10.5074],\n",
            "        [ 8.1540],\n",
            "        [ 9.6553],\n",
            "        ...,\n",
            "        [11.4565],\n",
            "        [40.6253],\n",
            "        [ 8.2310]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 198, Loss: 161.5533\n",
            "tensor([[ 8.8918],\n",
            "        [10.1015],\n",
            "        [ 9.5785],\n",
            "        ...,\n",
            "        [10.5249],\n",
            "        [38.3057],\n",
            "        [ 8.4218]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 199, Loss: 164.6942\n",
            "tensor([[ 8.6695],\n",
            "        [ 8.3199],\n",
            "        [ 7.3343],\n",
            "        ...,\n",
            "        [ 7.1256],\n",
            "        [19.9145],\n",
            "        [ 7.2719]], grad_fn=<AddmmBackward0>)\n",
            "Epoch: 200, Loss: 166.9147\n"
          ]
        }
      ],
      "source": [
        "model = MLP(hidden_channels=128)\n",
        "criterion = torch.nn.MSELoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data.x)\n",
        "      print(out)  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "for epoch in range(1, 201):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OWGw54wRd98"
      },
      "source": [
        "## Graph Neural Network (GNN)\n",
        "\n",
        "We can easily convert our MLP to a GNN by swapping the `torch.nn.Linear` layers with PyG's GNN operators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmXWs1dKIzD8",
        "outputId": "765572c9-9430-4910-f792-739646d28666"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GCN(\n",
            "  (conv1): GCNConv(50, 128)\n",
            "  (conv2): GCNConv(128, 1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(1234567)\n",
        "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "model = GCN(hidden_channels=128)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3TAi69zI1bO",
        "outputId": "3612214a-b8ee-4bde-e0e4-914558cdfb95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([17425])) that is different to the input size (torch.Size([17425, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001, Loss: 1323.5835\n",
            "Epoch: 002, Loss: 2849.7065\n",
            "Epoch: 003, Loss: 536.1916\n",
            "Epoch: 004, Loss: 1004.7610\n",
            "Epoch: 005, Loss: 2706.7317\n",
            "Epoch: 006, Loss: 1573.7823\n",
            "Epoch: 007, Loss: 3443.7905\n",
            "Epoch: 008, Loss: 3125.0439\n",
            "Epoch: 009, Loss: 1248.5557\n",
            "Epoch: 010, Loss: 1056.4447\n",
            "Epoch: 011, Loss: 4458.5669\n",
            "Epoch: 012, Loss: 1490.4191\n",
            "Epoch: 013, Loss: 1379.6553\n",
            "Epoch: 014, Loss: 1014.0363\n",
            "Epoch: 015, Loss: 769.5665\n",
            "Epoch: 016, Loss: 2062.3748\n",
            "Epoch: 017, Loss: 838.6727\n",
            "Epoch: 018, Loss: 873.5323\n",
            "Epoch: 019, Loss: 383.8441\n",
            "Epoch: 020, Loss: 753.3388\n",
            "Epoch: 021, Loss: 1534.9458\n",
            "Epoch: 022, Loss: 992.3315\n",
            "Epoch: 023, Loss: 698.8753\n",
            "Epoch: 024, Loss: 1265.1472\n",
            "Epoch: 025, Loss: 647.7196\n",
            "Epoch: 026, Loss: 587.6000\n",
            "Epoch: 027, Loss: 631.4578\n",
            "Epoch: 028, Loss: 743.4376\n",
            "Epoch: 029, Loss: 381.4366\n",
            "Epoch: 030, Loss: 337.9151\n",
            "Epoch: 031, Loss: 441.8435\n",
            "Epoch: 032, Loss: 345.7970\n",
            "Epoch: 033, Loss: 436.6377\n",
            "Epoch: 034, Loss: 378.3740\n",
            "Epoch: 035, Loss: 568.4542\n",
            "Epoch: 036, Loss: 696.7635\n",
            "Epoch: 037, Loss: 500.8578\n",
            "Epoch: 038, Loss: 428.2036\n",
            "Epoch: 039, Loss: 336.5660\n",
            "Epoch: 040, Loss: 346.4543\n",
            "Epoch: 041, Loss: 278.0534\n",
            "Epoch: 042, Loss: 263.0810\n",
            "Epoch: 043, Loss: 465.1024\n",
            "Epoch: 044, Loss: 290.8719\n",
            "Epoch: 045, Loss: 477.0868\n",
            "Epoch: 046, Loss: 292.0290\n",
            "Epoch: 047, Loss: 408.1880\n",
            "Epoch: 048, Loss: 367.7303\n",
            "Epoch: 049, Loss: 243.1378\n",
            "Epoch: 050, Loss: 301.7957\n",
            "Epoch: 051, Loss: 266.8723\n",
            "Epoch: 052, Loss: 355.4493\n",
            "Epoch: 053, Loss: 362.4804\n",
            "Epoch: 054, Loss: 242.2235\n",
            "Epoch: 055, Loss: 311.2612\n",
            "Epoch: 056, Loss: 255.2282\n",
            "Epoch: 057, Loss: 359.1063\n",
            "Epoch: 058, Loss: 395.9789\n",
            "Epoch: 059, Loss: 295.2179\n",
            "Epoch: 060, Loss: 233.3281\n",
            "Epoch: 061, Loss: 234.6519\n",
            "Epoch: 062, Loss: 234.3344\n",
            "Epoch: 063, Loss: 240.5238\n",
            "Epoch: 064, Loss: 300.0315\n",
            "Epoch: 065, Loss: 282.1310\n",
            "Epoch: 066, Loss: 241.9807\n",
            "Epoch: 067, Loss: 243.3369\n",
            "Epoch: 068, Loss: 271.3701\n",
            "Epoch: 069, Loss: 231.0461\n",
            "Epoch: 070, Loss: 212.0810\n",
            "Epoch: 071, Loss: 225.3467\n",
            "Epoch: 072, Loss: 224.4513\n",
            "Epoch: 073, Loss: 213.8961\n",
            "Epoch: 074, Loss: 223.0802\n",
            "Epoch: 075, Loss: 221.0318\n",
            "Epoch: 076, Loss: 240.2580\n",
            "Epoch: 077, Loss: 221.7378\n",
            "Epoch: 078, Loss: 227.1503\n",
            "Epoch: 079, Loss: 223.3695\n",
            "Epoch: 080, Loss: 225.5057\n",
            "Epoch: 081, Loss: 236.7458\n",
            "Epoch: 082, Loss: 210.0965\n",
            "Epoch: 083, Loss: 248.0006\n",
            "Epoch: 084, Loss: 223.8030\n",
            "Epoch: 085, Loss: 232.1402\n",
            "Epoch: 086, Loss: 209.4780\n",
            "Epoch: 087, Loss: 234.6303\n",
            "Epoch: 088, Loss: 218.2210\n",
            "Epoch: 089, Loss: 204.8157\n",
            "Epoch: 090, Loss: 214.4050\n",
            "Epoch: 091, Loss: 212.0973\n",
            "Epoch: 092, Loss: 214.5957\n",
            "Epoch: 093, Loss: 204.5921\n",
            "Epoch: 094, Loss: 226.5412\n",
            "Epoch: 095, Loss: 222.3667\n",
            "Epoch: 096, Loss: 202.6884\n",
            "Epoch: 097, Loss: 201.6968\n",
            "Epoch: 098, Loss: 197.9577\n",
            "Epoch: 099, Loss: 213.3917\n",
            "Epoch: 100, Loss: 211.0648\n"
          ]
        }
      ],
      "source": [
        "model = GCN(hidden_channels=128)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "criterion = torch.nn.MSELoss()\n",
        "\n",
        "def train():\n",
        "      model.train()\n",
        "      optimizer.zero_grad()  # Clear gradients.\n",
        "      out = model(data.x, data.edge_index)  # Perform a single forward pass.\n",
        "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
        "      loss.backward()  # Derive gradients.\n",
        "      optimizer.step()  # Update parameters based on gradients.\n",
        "      return loss\n",
        "\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKeqHqoDKdFl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Node regression Neural Methods",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}